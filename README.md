# Azure Medallion Architecture â€“ Batch & Streaming (ADF â€¢ Databricks â€¢ Event Hubs â€¢ Delta â€¢ Power BI)

This repository contains a **production-style implementation** of the Medallion Architecture (Bronze â†’ Silver â†’ Gold) on **Microsoft Azure** for **both batch and streaming** data pipelines.

## ğŸ“Œ Architecture

**Batch (ADF â†’ ADLS Gen2 Bronze â†’ Databricks â†’ Silver/Gold â†’ Power BI)**  
![Batch](resources/azure_batch_pipeline_v2.png)

**Streaming (Event Hubs â†’ Databricks Structured Streaming/Autoloader â†’ Silver/Gold â†’ Power BI)**  
![Streaming](resources/azure_streaming_pipeline_v2.png)

**Combined View**  
![Combined](resources/azure_combined_medallion_v2.png)

## ğŸ§± Components
- **Azure Data Factory** â€“ Orchestration of batch ingestion to ADLS Gen2 (Bronze).
- **Azure Databricks (PySpark)** â€“ Transformations to build Delta **Silver/Gold**; Structured Streaming for real time.
- **Azure Event Hubs** â€“ Real-time ingestion for product reviews/events.
- **Delta Lake** â€“ ACID, schema enforcement/evolution, time travel.
- **Power BI (DirectQuery)** â€“ Live analytics on Gold via Databricks SQL Warehouse.
- **Unity Catalog** â€“ Optional governance/RBAC.
- **Azure Monitor / Log Analytics** â€“ Observability.

## âš™ï¸ Workflows

### Batch
1. **Ingest (ADF)** raw sales/product/inventory â†’ **ADLS Gen2 Bronze**
2. **Transform (Databricks)** cleanse/standardize â†’ **Silver**
3. **Aggregate (Databricks)** star-schema/curated marts â†’ **Gold**
4. **Serve (Databricks SQL + Power BI)** DirectQuery models

### Streaming
1. **Ingest (Event Hubs)** product reviews/events
2. **Process (Databricks Structured Streaming + Autoloader)** with sentiment logic
3. **Persist (Delta)** Bronze â†’ Silver â†’ Gold
4. **Serve (Power BI)** sub-minute dashboards

## ğŸ“ Repository Structure
```
azure-medallion-pipeline/
â”œâ”€ batch/
â”‚  â”œâ”€ notebooks/
â”‚  â”‚  â”œâ”€ bronze_ingestion.py
â”‚  â”‚  â”œâ”€ silver_transformations.py
â”‚  â”‚  â””â”€ gold_aggregations.py
â”‚  â””â”€ adf_pipelines/
â”‚     â””â”€ pipeline_bronze.json   # Export your ADF pipeline ARM here
â”œâ”€ streaming/
â”‚  â”œâ”€ notebooks/
â”‚  â”‚  â”œâ”€ eventhubs_ingestion.py
â”‚  â”‚  â””â”€ sentiment_analysis.py
â”‚  â””â”€ config/
â”‚     â””â”€ eventhubs_config_example.json
â”œâ”€ resources/
â”‚  â”œâ”€ azure_batch_pipeline_v2.png
â”‚  â”œâ”€ azure_streaming_pipeline_v2.png
â”‚  â””â”€ azure_combined_medallion_v2.png
â”œâ”€ .github/workflows/ci.yml
â”œâ”€ .gitignore
â”œâ”€ LICENSE
â””â”€ README.md
```

## ğŸš€ Getting Started
1. **Create Azure resources:** ADLS Gen2, Databricks workspace, ADF, Event Hubs.
2. **Secrets:** Use **Azure Key Vault** / Databricks secrets. Do **not** commit credentials.
3. **ADF:** Export your pipeline ARM JSON into `batch/adf_pipelines/` (Manage â†’ ARM template).
4. **Databricks notebooks:** Export as `.py` and place under `batch/notebooks/` and `streaming/notebooks/`.
5. **Configure streaming:** Copy `streaming/config/eventhubs_config_example.json` â†’ `eventhubs_config.json` (not committed).
6. **Power BI:** Connect to Databricks SQL Warehouse (DirectQuery). Add screenshots to `resources/` if desired.

## ğŸ“ˆ Performance & Impact (example targets)
- Batch: reduced reporting latency to **< 1 hour**.
- Streaming: **< 60 seconds** E2E latency; scalable to **thousands of events/sec**.
- Cost: **~30% savings** via autoscaling, OPTIMIZE, partition pruning.

## ğŸ›¡ï¸ Security & Governance
- Managed Identity + OAuth for storage.
- Secrets in Key Vault (no keys in code).
- Unity Catalog for RBAC and lineage; Purview optional.

## ğŸ”§ CI (optional)
GitHub Action runs lint checks on notebooks/py files and validates JSON.

---

> **Note:** Replace placeholder notebooks and ADF JSON with your actual code. Never commit secrets.
